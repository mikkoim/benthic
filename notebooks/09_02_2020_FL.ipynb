{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-02-2020_FL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz-Dn26br4-R"
      },
      "source": [
        "\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_capability())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeD-IzS9K7A9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d094902c-9f4c-49db-b422-5d101c12253f"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EueRfvPV6gQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b45d30d4-57c7-4254-c38b-1c2c58df21d6"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-vvOwWQ-TtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ad3a5d3c-1451-4b2d-e429-77522faca513"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acC_WmNh6h__"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/IDA.zip\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma3AI_eNJyTY"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/benthic/loadbm.py\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcxCsSm_-q0r"
      },
      "source": [
        "%%capture\n",
        "!unzip IDA.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmKlRjh4Ixbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1abec1fe-4941-448c-9017-e00bfb9abb47"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import ntpath\n",
        "import platform\n",
        "import matplotlib.pyplot as plt\n",
        "from loadbm import create_df, create_tf_dataset, prepare_for_training\n",
        "\n",
        "\n",
        "datapath = 'IDA/Separate lists with numbering/Machine learning splits'\n",
        "img_path = 'IDA/Images/'\n",
        "\n",
        "split = 1\n",
        "\n",
        "train_fname = 'train'+str(split)+'.txt'\n",
        "test_fname = 'test'+str(split)+'.txt'\n",
        "val_fname = 'val'+str(split)+'.txt'\n",
        "\n",
        "part_dat = False\n",
        "\n",
        "df_train = create_df(os.path.join(datapath, train_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "df_test = create_df(os.path.join(datapath, test_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "df_val = create_df(os.path.join(datapath, val_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df_train = shuffle(df_train)\n",
        "df_val = shuffle(df_val)\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>185335</th>\n",
              "      <td>IDA/Images/Limnius_vol126/1-Limnius_vol126.1.2...</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308974</th>\n",
              "      <td>IDA/Images/Simuliidae90/1-Simuliidae90.1.2016-...</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114516</th>\n",
              "      <td>IDA/Images/Hydraena67/1-Hydraena67.1.2016-09-1...</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67408</th>\n",
              "      <td>IDA/Images/Elmis_aen584/1-Elmis_aen584.1.2016-...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128874</th>\n",
              "      <td>IDA/Images/Hydropsyche_sil309/0-Hydropsyche_si...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     path  label\n",
              "185335  IDA/Images/Limnius_vol126/1-Limnius_vol126.1.2...     22\n",
              "308974  IDA/Images/Simuliidae90/1-Simuliidae90.1.2016-...     37\n",
              "114516  IDA/Images/Hydraena67/1-Hydraena67.1.2016-09-1...     12\n",
              "67408   IDA/Images/Elmis_aen584/1-Elmis_aen584.1.2016-...      8\n",
              "128874  IDA/Images/Hydropsyche_sil309/0-Hydropsyche_si...     15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk6XhlkMKo4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "abac620c-0f06-4a47-be52-2ec368dc1386"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "IMSIZE = (224,224,3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = create_tf_dataset(df_train, imsize=IMSIZE, onehot=True)\n",
        "\n",
        "val_ds = create_tf_dataset(df_val, imsize=IMSIZE, onehot=True)\n",
        "\n",
        "\n",
        "train_ds = prepare_for_training(train_ds, \n",
        "                                shuffle_buffer_size=1000,\n",
        "                                batch_size=BATCH_SIZE)\n",
        "\n",
        "val_ds = prepare_for_training(val_ds, \n",
        "                              shuffle_buffer_size=1000,\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "for image, label in train_ds.take(5):\n",
        "    print(image.shape)\n",
        "    print(label.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vrokTggUW2H"
      },
      "source": [
        "import tensorflow.keras.backend as K\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "\n",
        "    def loss(y,yhat):\n",
        "        \n",
        "      y = K.cast(y, tf.float32)\n",
        "      yhat = tf.convert_to_tensor(yhat, dtype=y.dtype)\n",
        "\n",
        "      ce = -K.sum(y*K.log(yhat+1e-7), axis=1, keepdims=True)\n",
        "      \n",
        "      p_t = (y * yhat)\n",
        "      alpha_factor = (y * alpha)\n",
        "      \n",
        "      modulating_factor = ((1.0 - p_t)**gamma)\n",
        "      \n",
        "      fl = K.sum(alpha_factor*modulating_factor*ce, axis=-1)\n",
        "  \n",
        "      return fl\n",
        "\n",
        "    return loss\n",
        "\n",
        "alpha = np.histogram(df_train['label'].values,bins=39)[0]\n",
        "alpha = 1-(alpha/np.sum(alpha))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVO7otL1QyZy"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "def get_pretrained(imsize=(224, 224, 3), classes=39):\n",
        "        base_model = InceptionV3(input_shape = imsize, \n",
        "                                 weights='imagenet', \n",
        "                                 include_top=False)\n",
        "        \n",
        "        base_model.trainable = True\n",
        "        \n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(256, activation='relu')(x)\n",
        "        predictions = Dense(classes, activation='softmax')(x)\n",
        "        \n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        \n",
        "        return model\n",
        "\n",
        "model = get_pretrained()\n",
        "\n",
        "loss = focal_loss(gamma=2.0, alpha=alpha)\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = loss,\n",
        "                  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZgvJtY-Q2PM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "7741de85-a3c5-4609-9139-89f929471728"
      },
      "source": [
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import datetime\n",
        "\n",
        "\n",
        "tr_steps = len(df_train)//BATCH_SIZE\n",
        "val_steps = len(df_val)//BATCH_SIZE\n",
        "\n",
        "model.fit(train_ds, \n",
        "          validation_data= val_ds, \n",
        "          steps_per_epoch= tr_steps, \n",
        "          epochs = 10,\n",
        "          validation_steps = val_steps)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 10043 steps, validate for 1434 steps\n",
            "Epoch 1/10\n",
            "10043/10043 [==============================] - 1618s 161ms/step - loss: 0.2798 - accuracy: 0.8391 - val_loss: 0.3534 - val_accuracy: 0.8304\n",
            "Epoch 2/10\n",
            "10043/10043 [==============================] - 1597s 159ms/step - loss: 0.0644 - accuracy: 0.9498 - val_loss: 0.3481 - val_accuracy: 0.8499\n",
            "Epoch 3/10\n",
            "10043/10043 [==============================] - 1597s 159ms/step - loss: 0.0358 - accuracy: 0.9710 - val_loss: 0.4424 - val_accuracy: 0.8067\n",
            "Epoch 4/10\n",
            "10043/10043 [==============================] - 1598s 159ms/step - loss: 0.0246 - accuracy: 0.9799 - val_loss: 0.3161 - val_accuracy: 0.8715\n",
            "Epoch 5/10\n",
            "10043/10043 [==============================] - 1600s 159ms/step - loss: 0.0195 - accuracy: 0.9844 - val_loss: 0.2830 - val_accuracy: 0.8871\n",
            "Epoch 6/10\n",
            "10043/10043 [==============================] - 1596s 159ms/step - loss: 0.0155 - accuracy: 0.9872 - val_loss: 0.3160 - val_accuracy: 0.8746\n",
            "Epoch 7/10\n",
            "10043/10043 [==============================] - 1599s 159ms/step - loss: 0.0131 - accuracy: 0.9895 - val_loss: 0.4222 - val_accuracy: 0.8545\n",
            "Epoch 8/10\n",
            "10043/10043 [==============================] - 1595s 159ms/step - loss: 0.0118 - accuracy: 0.9904 - val_loss: 0.3373 - val_accuracy: 0.8787\n",
            "Epoch 9/10\n",
            "10043/10043 [==============================] - 1592s 159ms/step - loss: 0.0102 - accuracy: 0.9920 - val_loss: 0.3744 - val_accuracy: 0.8577\n",
            "Epoch 10/10\n",
            "10043/10043 [==============================] - 1598s 159ms/step - loss: 0.0096 - accuracy: 0.9924 - val_loss: 0.3526 - val_accuracy: 0.8835\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f37ef872518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4QoLL4m52Nn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "402d40e1-dfc3-4625-f89b-ead795bd4d08"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(learning_rate=0.0001) #original 0.001\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch):\n",
        "    return 0.0001 * tf.math.exp(0.1 * (-epoch))\n",
        "\n",
        "lr_cb = LearningRateScheduler(scheduler)\n",
        "\n",
        "model.compile(optimizer = adam, loss = loss,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds, \n",
        "          validation_data= val_ds, \n",
        "          steps_per_epoch= tr_steps, \n",
        "          epochs = 5,\n",
        "          validation_steps = val_steps,\n",
        "          callbacks=[csv_logger, lr_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 10043 steps, validate for 1434 steps\n",
            "Epoch 1/5\n",
            "10043/10043 [==============================] - 1600s 159ms/step - loss: 0.0016 - accuracy: 0.9987 - val_loss: 0.2111 - val_accuracy: 0.9264\n",
            "Epoch 2/5\n",
            "10043/10043 [==============================] - 1596s 159ms/step - loss: 3.6863e-04 - accuracy: 0.9997 - val_loss: 0.2234 - val_accuracy: 0.9263\n",
            "Epoch 3/5\n",
            "10043/10043 [==============================] - 1598s 159ms/step - loss: 2.5809e-04 - accuracy: 0.9997 - val_loss: 0.2119 - val_accuracy: 0.9293\n",
            "Epoch 4/5\n",
            "10043/10043 [==============================] - 1598s 159ms/step - loss: 1.3902e-04 - accuracy: 0.9998 - val_loss: 0.2237 - val_accuracy: 0.9292\n",
            "Epoch 5/5\n",
            "10043/10043 [==============================] - 1598s 159ms/step - loss: 1.4602e-04 - accuracy: 0.9999 - val_loss: 0.2342 - val_accuracy: 0.9292\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3874b1c278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKh9VoPQ0Uu7"
      },
      "source": [
        "model.save('09-02-2020_cont_colab.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_TU5S5-0Z8G"
      },
      "source": [
        "!cp '09-02-2020_cont_colab.h5' \"/content/drive/My Drive/koulu_honmia/kandi19/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUXbmvd84VEv"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9OFVEmV4WvP"
      },
      "source": [
        "test_ds = create_tf_dataset(df_test, imsize=IMSIZE, onehot=True)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htSIMp_o4eHG"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/benthic/combine_insects.py\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg_5mmZy4zst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "674fc962-abf9-44b8-f082-09bb5d940335"
      },
      "source": [
        "preds = model.predict(test_ds, verbose=True)\n",
        "yhat = np.argmax(preds,axis=1)+1\n",
        "y_test = df_test['label']\n",
        "\n",
        "acc = np.sum(yhat==y_test)/len(y_test)\n",
        "print('Image accuracy: {:.4f}'.format(acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2897/2897 [==============================] - 150s 52ms/step\n",
            "Image accuracy: 0.9235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMrBm9fJ4-6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e4f81a80-bb9f-4518-9e9c-a30f5e7d634e"
      },
      "source": [
        "#%% Insect combine\n",
        "from combine_insects import add_insect_class, add_yhat\n",
        "\n",
        "df_test_preds = add_insect_class(df_test)\n",
        "\n",
        "# adding predictions to dataframe for insect-wise prediction\n",
        "df_test_preds = add_yhat(df_test_preds,yhat)\n",
        "\n",
        "dfg = df_test_preds.groupby(['label','insect'],as_index=False)['pred'].agg(lambda x:x.value_counts().index[0])\n",
        "\n",
        "acc_g = np.sum(dfg['pred']==dfg['label'])/len(dfg)\n",
        "print('Aggregate accuracy: {:.4f}'.format(acc_g))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aggregate accuracy: 0.9554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAzEiGGDipn4"
      },
      "source": [
        ""
      ]
    }
  ]
}