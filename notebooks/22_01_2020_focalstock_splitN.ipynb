{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22-01-2020_focalstock_splitN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz-Dn26br4-R"
      },
      "source": [
        "\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_capability())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeD-IzS9K7A9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d95236f8-90b3-4503-a14c-4c87e13a5b90"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EueRfvPV6gQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2369af09-51a2-4dad-8771-2e9d9e650e53"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-vvOwWQ-TtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8bec4b1c-57bf-40d8-d532-eea788792999"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acC_WmNh6h__"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/IDA.zip\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma3AI_eNJyTY"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/benthic/loadbm.py\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcxCsSm_-q0r"
      },
      "source": [
        "%%capture\n",
        "!unzip IDA.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmKlRjh4Ixbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "70fc15eb-70a9-40c0-fb22-a0f00ed1c8cc"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import ntpath\n",
        "import platform\n",
        "import matplotlib.pyplot as plt\n",
        "from loadbm import create_df, create_tf_dataset, prepare_for_training\n",
        "\n",
        "\n",
        "datapath = 'IDA/Separate lists with numbering/Machine learning splits'\n",
        "img_path = 'IDA/Images/'\n",
        "\n",
        "split = 3\n",
        "\n",
        "train_fname = 'train'+str(split)+'.txt'\n",
        "test_fname = 'test'+str(split)+'.txt'\n",
        "val_fname = 'val'+str(split)+'.txt'\n",
        "\n",
        "part_dat = False\n",
        "\n",
        "df_train = create_df(os.path.join(datapath, train_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "df_test = create_df(os.path.join(datapath, test_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "df_val = create_df(os.path.join(datapath, val_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df_train = shuffle(df_train)\n",
        "df_val = shuffle(df_val)\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>255634</th>\n",
              "      <td>IDA/Images/Oxyethira71/0-Oxyethira71.1.2016-07...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126144</th>\n",
              "      <td>IDA/Images/Hydropsyche_sil241/1-Hydropsyche_si...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320245</th>\n",
              "      <td>IDA/Images/Taeniopteryx_neb41/1-Taeniopteryx_n...</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94933</th>\n",
              "      <td>IDA/Images/Heptagenia_sul122/1-Heptagenia_sul1...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132411</th>\n",
              "      <td>IDA/Images/Hydropsyche_sil43/1-Hydropsyche_sil...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     path  label\n",
              "255634  IDA/Images/Oxyethira71/0-Oxyethira71.1.2016-07...     29\n",
              "126144  IDA/Images/Hydropsyche_sil241/1-Hydropsyche_si...     15\n",
              "320245  IDA/Images/Taeniopteryx_neb41/1-Taeniopteryx_n...     39\n",
              "94933   IDA/Images/Heptagenia_sul122/1-Heptagenia_sul1...     11\n",
              "132411  IDA/Images/Hydropsyche_sil43/1-Hydropsyche_sil...     15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk6XhlkMKo4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "950ef773-e036-4ab4-e01a-c52eaf5f0c58"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "IMSIZE = (224,224,3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = create_tf_dataset(df_train, imsize=IMSIZE, onehot=True)\n",
        "\n",
        "val_ds = create_tf_dataset(df_val, imsize=IMSIZE, onehot=True)\n",
        "\n",
        "\n",
        "train_ds = prepare_for_training(train_ds, \n",
        "                                shuffle_buffer_size=1000,\n",
        "                                batch_size=BATCH_SIZE)\n",
        "\n",
        "val_ds = prepare_for_training(val_ds, \n",
        "                              shuffle_buffer_size=1000,\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "for image, label in train_ds.take(5):\n",
        "    print(image.shape)\n",
        "    print(label.shape)\n",
        "    print(label)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]], shape=(32, 39), dtype=int64)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(32, 39), dtype=int64)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(32, 39), dtype=int64)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [1 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 1 0 0]], shape=(32, 39), dtype=int64)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 0 ... 1 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(32, 39), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVO7otL1QyZy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eafa52dc-88bf-44df-84da-3bfec5f9167d"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "\n",
        "def get_pretrained(imsize=(224, 224, 3), classes=39):\n",
        "        base_model = InceptionV3(input_shape = imsize, \n",
        "                                 weights='imagenet', \n",
        "                                 include_top=False)\n",
        "        \n",
        "        base_model.trainable = True\n",
        "        \n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(256, activation='relu')(x)\n",
        "        predictions = Dense(classes, activation='softmax')(x)\n",
        "        \n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        \n",
        "        return model\n",
        "\n",
        "model = get_pretrained()\n",
        "\n",
        "\n",
        "focal = tfa.losses.SigmoidFocalCrossEntropy()\n",
        "\n",
        "model.compile(optimizer = 'adam', loss = focal,\n",
        "                  metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZgvJtY-Q2PM"
      },
      "source": [
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import datetime\n",
        "\n",
        "csv_logger = CSVLogger('22-01-2020_colab_split3.log',append=True)\n",
        "\n",
        "tr_steps = len(df_train)//BATCH_SIZE\n",
        "val_steps = len(df_val)//BATCH_SIZE\n",
        "\n",
        "model.fit(train_ds, \n",
        "          validation_data= val_ds, \n",
        "          steps_per_epoch= tr_steps, \n",
        "          epochs = 10,\n",
        "          validation_steps = val_steps,\n",
        "          callbacks=[csv_logger])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4QoLL4m52Nn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a8ae725e-1253-421e-ef8a-881379cdca49"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(learning_rate=0.0001) #original 0.001\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch):\n",
        "    return 0.0001 * tf.math.exp(0.1 * (-epoch))\n",
        "\n",
        "lr_cb = LearningRateScheduler(scheduler)\n",
        "\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds, \n",
        "          validation_data= val_ds, \n",
        "          steps_per_epoch= tr_steps, \n",
        "          epochs = 5,\n",
        "          validation_steps = val_steps,\n",
        "          callbacks=[csv_logger, lr_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 10054 steps, validate for 1416 steps\n",
            "Epoch 1/5\n",
            "10054/10054 [==============================] - 1611s 160ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 0.4053 - val_accuracy: 0.9211\n",
            "Epoch 2/5\n",
            "10054/10054 [==============================] - 1603s 159ms/step - loss: 9.0462e-04 - accuracy: 0.9998 - val_loss: 0.4264 - val_accuracy: 0.9243\n",
            "Epoch 3/5\n",
            "10054/10054 [==============================] - 1607s 160ms/step - loss: 5.2232e-04 - accuracy: 0.9999 - val_loss: 0.4568 - val_accuracy: 0.9239\n",
            "Epoch 4/5\n",
            "10054/10054 [==============================] - 1605s 160ms/step - loss: 3.7591e-04 - accuracy: 0.9999 - val_loss: 0.4588 - val_accuracy: 0.9250\n",
            "Epoch 5/5\n",
            "10054/10054 [==============================] - 1608s 160ms/step - loss: 2.1681e-04 - accuracy: 0.9999 - val_loss: 0.4886 - val_accuracy: 0.9248\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fad0ceaa048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKh9VoPQ0Uu7"
      },
      "source": [
        "model.save('22-01-2020_cont_colab_split2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_TU5S5-0Z8G"
      },
      "source": [
        "!cp '22-01-2020_cont_colab_split2.h5' \"/content/drive/My Drive/koulu_honmia/kandi19/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUXbmvd84VEv"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9OFVEmV4WvP"
      },
      "source": [
        "test_ds = create_tf_dataset(df_test, imsize=IMSIZE, onehot=True)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htSIMp_o4eHG"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/benthic/combine_insects.py\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg_5mmZy4zst",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ce1f622f-3a57-4e37-ecd4-3edbb76a202d"
      },
      "source": [
        "preds = model.predict(test_ds, verbose=True)\n",
        "yhat = np.argmax(preds,axis=1)+1\n",
        "y_test = df_test['label']\n",
        "\n",
        "acc = np.sum(yhat==y_test)/len(y_test)\n",
        "print('Image accuracy: {:.4f}'.format(acc))\n",
        "\n",
        "np.save('22-01-2020_cont_colab_split2.npy', preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2904/2904 [==============================] - 143s 49ms/step\n",
            "Image accuracy: 0.9254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQqogRoN4Mgs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0e0d400c-8309-4127-df39-dab7b3acf5fb"
      },
      "source": [
        "!cp '22-01-2020_cont_colab_split2.npy' \"/content/drive/My Drive/koulu_honmia/kandi19/\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot stat '22-01-2020_cont_colab_split2.npy': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMrBm9fJ4-6D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c8a8a29d-ed11-486e-9956-8b1345627f31"
      },
      "source": [
        "#%% Insect combine\n",
        "from combine_insects import add_insect_class, add_yhat\n",
        "\n",
        "df_test_preds = add_insect_class(df_test)\n",
        "\n",
        "# adding predictions to dataframe for insect-wise prediction\n",
        "df_test_preds = add_yhat(df_test_preds,yhat)\n",
        "\n",
        "dfg = df_test_preds.groupby(['label','insect'],as_index=False)['pred'].agg(lambda x:x.value_counts().index[0])\n",
        "\n",
        "acc_g = np.sum(dfg['pred']==dfg['label'])/len(dfg)\n",
        "print('Aggregate accuracy: {:.4f}'.format(acc_g))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aggregate accuracy: 0.9576\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjd_PjTZ2rJQ"
      },
      "source": [
        ""
      ]
    }
  ]
}