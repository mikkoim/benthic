{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "24-01-2020_freeze.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "hz-Dn26br4-R"
      },
      "source": [
        "\n",
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_capability())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NeD-IzS9K7A9"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EueRfvPV6gQW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9abca50-7076-4c72-f2d9-9273933b20aa"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-vvOwWQ-TtC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c2adb162-1226-4261-82ac-2c41fe82fbc2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acC_WmNh6h__"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/IDA.zip\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma3AI_eNJyTY"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/benthic/loadbm.py\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcxCsSm_-q0r"
      },
      "source": [
        "%%capture\n",
        "!unzip IDA.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmKlRjh4Ixbk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a395140a-12cc-45cf-fbca-aa85d10ea52f"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import ntpath\n",
        "import platform\n",
        "import matplotlib.pyplot as plt\n",
        "from loadbm import create_df, create_tf_dataset, prepare_for_training\n",
        "\n",
        "\n",
        "datapath = 'IDA/Separate lists with numbering/Machine learning splits'\n",
        "img_path = 'IDA/Images/'\n",
        "\n",
        "split = 1\n",
        "\n",
        "train_fname = 'train'+str(split)+'.txt'\n",
        "test_fname = 'test'+str(split)+'.txt'\n",
        "val_fname = 'val'+str(split)+'.txt'\n",
        "\n",
        "part_dat = False\n",
        "\n",
        "df_train = create_df(os.path.join(datapath, train_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "df_test = create_df(os.path.join(datapath, test_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "df_val = create_df(os.path.join(datapath, val_fname),\n",
        "                     img_path,\n",
        "                     partial_dataset=part_dat,\n",
        "                     seed=123)\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df_train = shuffle(df_train)\n",
        "df_val = shuffle(df_val)\n",
        "\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>303833</th>\n",
              "      <td>IDA/Images/Simuliidae75/0-Simuliidae75.1.2016-...</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213420</th>\n",
              "      <td>IDA/Images/Nemoura_avi50/1-Nemoura_avi50.1.201...</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267071</th>\n",
              "      <td>IDA/Images/Polycentropus_irr43/0-Polycentropus...</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65385</th>\n",
              "      <td>IDA/Images/Elmis_aen541/0-Elmis_aen541.1.2016-...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320550</th>\n",
              "      <td>IDA/Images/Taeniopteryx_neb77/0-Taeniopteryx_n...</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     path  label\n",
              "303833  IDA/Images/Simuliidae75/0-Simuliidae75.1.2016-...     37\n",
              "213420  IDA/Images/Nemoura_avi50/1-Nemoura_avi50.1.201...     26\n",
              "267071  IDA/Images/Polycentropus_irr43/0-Polycentropus...     32\n",
              "65385   IDA/Images/Elmis_aen541/0-Elmis_aen541.1.2016-...      8\n",
              "320550  IDA/Images/Taeniopteryx_neb77/0-Taeniopteryx_n...     39"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rk6XhlkMKo4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "109a45fb-64dc-49e4-be23-533cc3cb3d6a"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "IMSIZE = (224,224,3)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_ds = create_tf_dataset(df_train, imsize=IMSIZE, onehot=True)\n",
        "\n",
        "val_ds = create_tf_dataset(df_val, imsize=IMSIZE, onehot=True)\n",
        "\n",
        "\n",
        "train_ds = prepare_for_training(train_ds, \n",
        "                                shuffle_buffer_size=1000,\n",
        "                                batch_size=BATCH_SIZE)\n",
        "\n",
        "val_ds = prepare_for_training(val_ds, \n",
        "                              shuffle_buffer_size=1000,\n",
        "                              batch_size=BATCH_SIZE)\n",
        "\n",
        "for image, label in train_ds.take(5):\n",
        "    print(image.shape)\n",
        "    print(label.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n",
            "(32, 224, 224, 3)\n",
            "(32, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVO7otL1QyZy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6f81216b-cf98-4d29-8ad2-138fe5c102ee"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "def get_pretrained(imsize=(224, 224, 3), classes=39):\n",
        "        base_model = InceptionV3(input_shape = imsize, \n",
        "                                 weights='imagenet', \n",
        "                                 include_top=False)\n",
        "        \n",
        "        base_model.trainable = False\n",
        "        \n",
        "        x = base_model.output\n",
        "        x = GlobalAveragePooling2D()(x)\n",
        "        x = Dense(256, activation='relu')(x)\n",
        "        predictions = Dense(classes, activation='softmax')(x)\n",
        "        \n",
        "        model = Model(inputs=base_model.input, outputs=predictions)\n",
        "        \n",
        "        return model\n",
        "\n",
        "model = get_pretrained()\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4QoLL4m52Nn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "a0ebc784-e390-437e-a7ba-b4903c3e487a"
      },
      "source": [
        "from tensorflow.keras.callbacks import CSVLogger\n",
        "import datetime\n",
        "\n",
        "csv_logger = CSVLogger('24-01-2020_2_colab.log',append=True)\n",
        "\n",
        "tr_steps = len(df_train)//BATCH_SIZE\n",
        "val_steps = len(df_val)//BATCH_SIZE\n",
        "\n",
        "model.fit(train_ds, \n",
        "          validation_data= val_ds, \n",
        "          steps_per_epoch= tr_steps, \n",
        "          epochs = 10,\n",
        "          validation_steps = val_steps,\n",
        "          callbacks=[csv_logger])\n",
        "\n",
        "for layer in model.layers:\n",
        "    layer.trainable = True\n",
        "    \n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds, \n",
        "          validation_data= val_ds, \n",
        "          steps_per_epoch= tr_steps, \n",
        "          epochs = 10,\n",
        "          validation_steps = val_steps,\n",
        "          callbacks=[csv_logger])\n",
        "\n",
        "#### Cont training #####\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "adam = Adam(learning_rate=0.0001) #original 0.001\n",
        "\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "def scheduler(epoch):\n",
        "    return 0.0001 * tf.math.exp(0.1 * (-epoch))\n",
        "\n",
        "lr_cb = LearningRateScheduler(scheduler)\n",
        "\n",
        "model.compile(optimizer = adam, loss = 'categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_ds, \n",
        "          validation_data= val_ds, \n",
        "          steps_per_epoch= tr_steps, \n",
        "          epochs = 5,\n",
        "          validation_steps = val_steps,\n",
        "          callbacks=[csv_logger, lr_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 10043 steps, validate for 1434 steps\n",
            "Epoch 1/10\n",
            "10043/10043 [==============================] - 697s 69ms/step - loss: 1.4705 - accuracy: 0.5577 - val_loss: 3.7572 - val_accuracy: 0.2341\n",
            "Epoch 2/10\n",
            "10043/10043 [==============================] - 664s 66ms/step - loss: 1.2149 - accuracy: 0.6259 - val_loss: 3.9903 - val_accuracy: 0.2523\n",
            "Epoch 3/10\n",
            "10043/10043 [==============================] - 660s 66ms/step - loss: 1.1300 - accuracy: 0.6501 - val_loss: 3.6593 - val_accuracy: 0.2660\n",
            "Epoch 4/10\n",
            "10043/10043 [==============================] - 658s 66ms/step - loss: 1.0816 - accuracy: 0.6640 - val_loss: 3.8750 - val_accuracy: 0.2431\n",
            "Epoch 5/10\n",
            "10043/10043 [==============================] - 660s 66ms/step - loss: 1.0473 - accuracy: 0.6729 - val_loss: 3.8989 - val_accuracy: 0.2496\n",
            "Epoch 6/10\n",
            "10043/10043 [==============================] - 659s 66ms/step - loss: 1.0183 - accuracy: 0.6816 - val_loss: 4.0564 - val_accuracy: 0.2443\n",
            "Epoch 7/10\n",
            "10043/10043 [==============================] - 657s 65ms/step - loss: 1.0003 - accuracy: 0.6877 - val_loss: 3.7701 - val_accuracy: 0.2657\n",
            "Epoch 8/10\n",
            "10043/10043 [==============================] - 660s 66ms/step - loss: 0.9852 - accuracy: 0.6923 - val_loss: 4.2083 - val_accuracy: 0.2386\n",
            "Epoch 9/10\n",
            "10043/10043 [==============================] - 660s 66ms/step - loss: 0.9731 - accuracy: 0.6960 - val_loss: 3.7864 - val_accuracy: 0.2591\n",
            "Epoch 10/10\n",
            "10043/10043 [==============================] - 661s 66ms/step - loss: 0.9573 - accuracy: 0.7007 - val_loss: 4.2595 - val_accuracy: 0.2412\n",
            "Train for 10043 steps, validate for 1434 steps\n",
            "Epoch 1/10\n",
            "10043/10043 [==============================] - 1628s 162ms/step - loss: 0.4200 - accuracy: 0.8653 - val_loss: 1.1372 - val_accuracy: 0.7299\n",
            "Epoch 2/10\n",
            "10043/10043 [==============================] - 1619s 161ms/step - loss: 0.1160 - accuracy: 0.9621 - val_loss: 0.6598 - val_accuracy: 0.8415\n",
            "Epoch 3/10\n",
            "10043/10043 [==============================] - 1618s 161ms/step - loss: 0.0641 - accuracy: 0.9792 - val_loss: 0.4853 - val_accuracy: 0.8809\n",
            "Epoch 4/10\n",
            "10043/10043 [==============================] - 1618s 161ms/step - loss: 0.0440 - accuracy: 0.9858 - val_loss: 0.7035 - val_accuracy: 0.8552\n",
            "Epoch 5/10\n",
            "10043/10043 [==============================] - 1615s 161ms/step - loss: 0.0344 - accuracy: 0.9891 - val_loss: 0.9575 - val_accuracy: 0.8217\n",
            "Epoch 6/10\n",
            "10043/10043 [==============================] - 1618s 161ms/step - loss: 0.0287 - accuracy: 0.9909 - val_loss: 0.5475 - val_accuracy: 0.8941\n",
            "Epoch 7/10\n",
            "10043/10043 [==============================] - 1619s 161ms/step - loss: 0.0240 - accuracy: 0.9925 - val_loss: 0.6121 - val_accuracy: 0.8915\n",
            "Epoch 8/10\n",
            "10043/10043 [==============================] - 1620s 161ms/step - loss: 0.0203 - accuracy: 0.9936 - val_loss: 0.6405 - val_accuracy: 0.8926\n",
            "Epoch 9/10\n",
            " 1111/10043 [==>...........................] - ETA: 22:52 - loss: 0.0200 - accuracy: 0.9938"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKh9VoPQ0Uu7"
      },
      "source": [
        "model.save('24-01-2020_cont_colab_split2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_TU5S5-0Z8G"
      },
      "source": [
        "!cp '24-01-2020_cont_colab_split2.h5' \"/content/drive/My Drive/koulu_honmia/kandi19/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUXbmvd84VEv"
      },
      "source": [
        "Evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9OFVEmV4WvP"
      },
      "source": [
        "test_ds = create_tf_dataset(df_test, imsize=IMSIZE, onehot=True)\n",
        "test_ds = test_ds.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htSIMp_o4eHG"
      },
      "source": [
        "!cp \"/content/drive/My Drive/koulu_honmia/kandi19/benthic/combine_insects.py\" /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg_5mmZy4zst"
      },
      "source": [
        "preds = model.predict(test_ds, verbose=True)\n",
        "yhat = np.argmax(preds,axis=1)+1\n",
        "y_test = df_test['label']\n",
        "\n",
        "acc = np.sum(yhat==y_test)/len(y_test)\n",
        "print('Image accuracy: {:.4f}'.format(acc))\n",
        "\n",
        "np.save('24-01-2020_cont_colab_split2.npy', preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBJscekrY4Mt"
      },
      "source": [
        "!cp '24-01-2020_cont_colab_split2.npy' \"/content/drive/My Drive/koulu_honmia/kandi19/\" "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMrBm9fJ4-6D"
      },
      "source": [
        "#%% Insect combine\n",
        "from combine_insects import add_insect_class, add_yhat\n",
        "\n",
        "df_test_preds = add_insect_class(df_test)\n",
        "\n",
        "# adding predictions to dataframe for insect-wise prediction\n",
        "df_test_preds = add_yhat(df_test_preds,yhat)\n",
        "\n",
        "dfg = df_test_preds.groupby(['label','insect'],as_index=False)['pred'].agg(lambda x:x.value_counts().index[0])\n",
        "\n",
        "acc_g = np.sum(dfg['pred']==dfg['label'])/len(dfg)\n",
        "print('Aggregate accuracy: {:.4f}'.format(acc_g))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtb25xasb7KF"
      },
      "source": [
        ""
      ]
    }
  ]
}